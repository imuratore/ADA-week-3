---
title: "homework"
author: Isabella Muratore
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# R Markdown

# homework 02

## What is the probability that she will hear more than 8 calls during any given session?
### using a poisson probability distribution to get the upper tail using 9 position along the distribution because that's how I interpretted "more than 8"

```{r}

ppois(9, lambda=15, lower=FALSE) 

```

#### returns 0.93 etc, so the answer is a ~93% probability of more than 8 assuming the mean is accurate

## What is the probability that she will hear no calls in a session?
### using a poisson probability distribution to get the lower tail using 0 as the position along the distribution

```{r}

ppois(0, lambda=15)

```

#### returns 0.0000003059023, so a 0.00003059023% probability, quite unlikely

## What is the probability that she will hear exactly 3 calls in a session?
### using a poisson density distribution (since this is just for one specific value) to get the probability of hearing exactly 3 calls

```{r}

dpois(3, lambda=15)

```

#### returns 0.0001720701, so 0.01720701% probability, also unlikely

## Plot the relevant Poisson mass function over the values in range 0 ≤ x ≤ 30
### Using dpois from 0 to 30 and plotting as points over x = a vector from 0 to 30

```{r}

z <- dpois(0:30, lambda=15)

x <- c(0:30)

barplot(z, names.arg = x, space = 0, xlab = "x", ylab = "Pr(X = x)", main = "Poisson Mass Function")

```

####

## Simulate 104 results from this distribution (i.e., 2 years of Saturday monitoring sessions).
### 

```{r}

x <- rpois(104, lambda=15)

#ignore
#set <- NULL  # sets up a dummy variable to hold our 10000 simulations
#n <- 104
#for (i in 1:104) {
#    set[i] <- mean(sample(x, n, replace = TRUE))
#}

#set

x

```

## Plot the simulated results using hist() and use xlim() to set the horizontal limits to be from 0 to 30. How does your histogram compare to the shape of the probability mass function you plotted above?

### applying hist() with an x range of 0-30 to "set", which we filled using the bootstrapping loop above

```{r}

hist(x, xlim=range(c(0:30)))



#### This distribution is much narrower than the one made using the probability mass function. This happens because increasing the sample size or number of simulated values tightens the distribution and decreases variance/standard deviation because n is in the denominator of these equations.

```

#### This distribution is much less smooth and symmetrical than the one made using the probability mass function. The probability mass function histogram is more "perfect" because it has an infinite sample size, as opposed to 104, and this tightens the distribution and decreases variance/standard deviation because n is in the denominator of these equations.

# second homework problem
## Load in the dataset “zombies.csv” from my GitHub repo
### downloading zombies.csv from GitHub using curl, formatting using read.csv with commas as separation

```{r}
library(curl)
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN597_Fall17/zombies.csv")

d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)

```
## Calculate the population mean and standard deviation for each quantitative random variable (height, weight, age, number of zombies killed, and years of education). NOTE: You will not want to use the built in var() and  sd() commands as these are for samples.
### using mean function to average the height variable

```{r}

h <- d$height

mean(h)

w <- d$weight

mean(w)

a <- d$age

mean(a)

z <- d$zombies_killed

mean(z)

y <- d$years_of_education

mean(y)

```
####
###

```{r}
pop_v <- function(x) {
    sum((x - mean(x))^2)/(length(x))
}
pop_v(h)

pop_v(w)

pop_v(a)

pop_v(z)

pop_v(y)

```
####
###

```{r}

pop_sd <- function(x) {
    sqrt(pop_v(x))
}
pop_sd(h)

pop_sd(w)

pop_sd(a)

pop_sd(z)

pop_sd(y)

```
## Use {ggplot} and make boxplots of each of these variables by gender.
###
```{r}
library(ggplot2)

p <- ggplot(data = d, aes(x = gender, y = h))
p <- p + geom_boxplot()
p <- p + theme(axis.text.x = element_text(angle = 90))
p <- p + ylab("height")
p

p <- ggplot(data = d, aes(x = gender, y = w))
p <- p + geom_boxplot()
p <- p + theme(axis.text.x = element_text(angle = 90))
p <- p + ylab("weight")
p

p <- ggplot(data = d, aes(x = gender, y = a))
p <- p + geom_boxplot()
p <- p + theme(axis.text.x = element_text(angle = 90))
p <- p + ylab("age")
p

p <- ggplot(data = d, aes(x = gender, y = z))
p <- p + geom_boxplot()
p <- p + theme(axis.text.x = element_text(angle = 90))
p <- p + ylab("zombies killed")
p

p <- ggplot(data = d, aes(x = gender, y = y))
p <- p + geom_boxplot()
p <- p + theme(axis.text.x = element_text(angle = 90))
p <- p + ylab("years of education")
p



```

##Use {ggplot} and make scatterplots of height and weight in relation to age. Do these variables seem to be related? In what way?
###

```{r}

p <- ggplot(data = d, aes(x = age, y = height))  # first, we build a plot object
p <- p + xlab("age") + ylab("height")  # then we modify the axis labels
p <- p + geom_point()  # then we make a scatterplot
p <- p + theme(legend.position = "bottom", legend.title = element_blank())  # then we modify the legend
p  # and, finally, we plot the object

p <- ggplot(data = d, aes(x = age, y = weight))  # first, we build a plot object
p <- p + xlab("age") + ylab("weight")  # then we modify the axis labels
p <- p + geom_point()  # then we make a scatterplot
p <- p + theme(legend.position = "bottom", legend.title = element_blank())  # then we modify the legend
p  # and, finally, we plot the object
```
#### Without quantifying correlation, I would say that both height and weight are positively correlated to age, with the correlation between weight and age appearing slightly less robust than that between height and age.

## Using histograms and Q-Q plots, check whether the quantitative variables seem to be drawn from a normal distribution. Which seem to be and which do not (hint: not all are drawn from the normal distribution)? For those that are not, can you determine what common distribution they are drawn from?
```{r}
hist(h)

qqnorm(h, main = "Height Normal Q-Q Plot")
qqline(h, col = "gray")
#normal

hist(w)

qqnorm(w, main = "Weight Normal Q-Q Plot")
qqline(w, col = "gray")
#not normal?

hist(a)

qqnorm(a, main = "Age Normal Q-Q Plot")
qqline(a, col = "gray")
#normal?

hist(z)

qqnorm(z, main = "Zombies Killed Normal Q-Q Plot")
qqline(z, col = "gray")
#def not normal

hist(y)

qqnorm(y, main = "Education Normal Q-Q Plot")
qqline(y, col = "gray")
#def not normal

```
####

## Now use the sample() function to sample ONE subset of 30 zombies (without replacement) from this population and calculate the mean and sample standard deviation for each variable. Also estimate the standard error for each variable and construct the 95% confidence interval for each mean. Note that for the variables that are not drawn from the normal distribution, you will need to base your estimate of the CIs on some different distribution.
###

```{r}
k <- 1  # number of samples
n <- 30  # size of each sample
s <- NULL  # dummy variable to hold each sample
for (i in 1:k) {
    s[[i]] <- sample(h, size = n, replace = FALSE)
}

m <- NULL
for (i in 1:k) {
    m[i] <- mean(s[[i]])
}
mean(m)  

stdev <- NULL
for (i in 1:k) {
    stdev[i] <- sd(s[[i]])
}
sem <- stdev/sqrt(n)  # a vector of SEs estimated from each sample 

sigma <- sqrt(sum((h - mean(h))^2)/length(h))

pop_se <- sigma/sqrt(n)
pop_se 

upper <- mean(h) + qnorm(0.95, mean = mean(h), sd = stdev) * pop_se
lower <- mean(h) + qnorm(0.05, mean = mean(h), sd = stdev) * pop_se  
ci <- c(lower, upper)
ci

#alternatively
#upper <- mean(h) + qpois(0.95, mean = mean(h), sd = stdev) * pop_se
#lower <- mean(h) + qpois(0.05, mean = mean(h), sd = stdev) * pop_se  
#ci <- c(lower, upper)
#ci

#alternatively
#upper <- mean(h) + qbinom(0.95, mean = mean(h), sd = stdev) * pop_se
#lower <- mean(h) + qbinom(0.05, mean = mean(h), sd = stdev) * pop_se  
#ci <- c(lower, upper)
#ci


```
####

## Now draw 99 more random samples of 30 zombies out and calculate the mean for each of the these samples. Together with the first sample you drew out, you now have a set of 100 means for each variable (each based on 30 observations), which constitutes a sampling distribution for each variable. What are the means and standard deviations of this distribution for each variable? How do the standard deviations compare to the standard errors estimated in [5]? What do these sampling distributions look like? Are they normally distributed? What about for those variables that you concluded were not originally drawn from a normal distribution?
###

```{r}
k <- 99  # number of samples
n <- 30  # size of each sample
s <- NULL  # dummy variable to hold each sample
for (i in 1:k) {
    s[[i]] <- sample(h, size = n, replace = FALSE)
}

m <- NULL
for (i in 1:k) {
    m[i] <- mean(s[[i]])
}
mean(m)  

stdev <- NULL
for (i in 1:k) {
    stdev[i] <- sd(s[[i]])
}


```
####




